---
title: "CyTOF Sample Clustering Report"
author: "Michael de Kok"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: TRUE
    theme: united
    css: style.css
    version: 1.3
params:
  pregating_channels:
    label: "If the following markers exist, assign them to Pregating Channels and do not plot/score them. Seperated by spaces."
    value: "Ce140Di Ir191Di Ir193Di Rh103Di"
    input: text
  instrument_channels:
    label: "If the following channels exist, assign them to Instrument Channels and do not plot/score them. Sperated by spaces."
    value: "Time Event_length Center SampleID Offset Width Residual FileNum"
    input: text
  pregates:
    label: "Perform the following pregates (with format 'channel{<or>}threshold'). Seperated by spaces."
    value: ""
    input: text
  SPILLOVER:
    label: "Perform the following actions regarding Spillover:"
    value: "Use Spillovers for Scoring"
    choices: ["Do Nothing", "Use Spillovers for Scoring", "Use Spillovers for Scoring & Compensate Data in Graphs"]
    input: select
  SPILLOVERMATRIX:
    label: "If previous is not 'Do Nothing', use the following Spillover Matrix file."
    value: "../Supplemental Data/Spillover_Fluidigm.xlsx"
    input: file
  markernames:
    label: "Save files with marker names instead of metal names."
    value: FALSE
    input: checkbox     
  arcsinh: 
    label: "Perform ArcSinh transformation on data."
    value: TRUE
    input: checkbox
  arcsinhcofac: 
    label: "Cofactor to use during ArcSinh transformation."
    value: 5
    input: numeric      
  UMAP:
    label: "Cluster Data using UMAP Clustering (faster)."
    value: FALSE
    input: checkbox     
  TSNE: 
    label: "Cluster Data using TSNE Clustering."
    value: TRUE
    input: checkbox
  FLOWSOM: 
    label: "Cluster Data using FLOWSOM Meta Tree Clustering."
    value: TRUE
    input: checkbox  
---

Adapted from http://biosurf.wiki/#!/wiki/cytof, Nowicka et al. (2019), Amir et al. (2018), and the unpublished work of Jan Verhoeff

# 1. Loading of Packages

```{r packages, echo = TRUE, results='hide', message=FALSE}

## Check if all necessary packages are installed by trying to load each
PACKAGES_TOTAL <- c('abind', 'askpass', 'assertthat', 'backports', 'base64enc', 'beachmat', 'beeswarm', 'BH', 'Biobase', 'BiocGenerics', 'BiocInstaller', 'BiocNeighbors', 'BiocParallel', 'BiocSingular', 'bitops', 'brew', 'callr', 'car', 'carData', 'CATALYST', 'caTools', 'cellranger', 'circlize', 'cli', 'clipr', 'clisymbols', 'clue', 'colorspace', 'colourpicker', 'colorRamps', 'commonmark', 'ComplexHeatmap', 'ConsensusClusterPlus', 'corpcor', 'covr', 'crayon', 'crosstalk', 'curl', 'cydar', 'cytofCore', 'cytofkit', 'cytolib', 'cytutils', 'data.table', 'DelayedArray', 'DelayedMatrixStats', 'DEoptimR', 'desc', 'destiny', 'devtools', 'digest', 'doParallel', 'dotCall64', 'dplyr', 'drc', 'DT', 'e1071', 'edgeR', 'ellipsis', 'evaluate', 'fansi', 'fastmap', 'fields', 'flowCL', 'flowCore', 'flowDensity', 'FlowSOM', 'flowUtils', 'flowViz', 'flowWorkspace', 'forcats', 'foreach', 'formatR', 'fs', 'futile.logger', 'futile.options', 'gdata', 'GenomeInfoDb', 'GenomeInfoDbData', 'GenomicRanges', 'GEOmap', 'GetoptLong', 'ggbeeswarm', 'ggplot2', 'ggrepel', 'ggridges', 'ggthemes', 'gh', 'git2r', 'GlobalOptions', 'glue', 'gplots', 'graph', 'gridBase', 'gridExtra', 'gtable', 'gtools', 'haven', 'HDF5Array', 'hexbin', 'highr', 'hms', 'htmltools', 'htmlwidgets', 'httpuv', 'httr', 'IDPmisc', 'igraph', 'ini', 'installr', 'IRanges', 'irlba', 'iterators', 'jsonlite', 'knitr', 'kableExtra', 'kohonen', 'labeling', 'laeken', 'lambda.r', 'later', 'latticeExtra', 'lazyeval', 'lifecycle', 'limma', 'lme4', 'lmtest', 'locfit', 'magrittr', 'maps', 'maptools', 'markdown', 'MASS', 'MatrixModels', 'matrixStats', 'MBA', 'MEM', 'memoise', 'mime', 'miniUI', 'minqa', 'miscTools', 'multcomp', 'munsell', 'mvtnorm', 'ncdfFlow', 'nloptr', 'nnls', 'openssl', 'openxlsx', 'pbkrtest', 'pcaPP', 'pdist', 'permute', 'pheatmap', 'pillar', 'pkgbuild', 'pkgconfig', 'pkgload', 'plogr', 'plotly', 'plotrix', 'plyr', 'png', 'praise', 'prettyunits', 'processx', 'progress', 'promises', 'proxy', 'ps', 'purrr', 'quantreg', 'R6', 'Radviz', 'ranger', 'RANN', 'RBGL', 'rcmdcheck', 'RColorBrewer', 'Rcpp', 'RcppAnnoy', 'RcppArmadillo', 'RcppEigen', 'RcppHNSW', 'RcppParallel', 'RCurl', 'readr', 'readxl', 'rematch', 'remotes', 'reshape2', 'rex', 'RFOC', 'rgeos', 'Rgraphviz', 'rhdf5', 'Rhdf5lib', 'rio', 'rjson', 'rlang', 'rmarkdown', 'robustbase', 'roxygen2', 'Rphenograph', 'RPMG', 'rprojroot', 'RProtoBufLib', 'rrcov', 'RSEIS', 'rstudioapi', 'rsvd', 'Rtsne', 'RUnit', 'rversions', 'Rwave', 'S4Vectors', 'sandwich', 'scales', 'scater', 'scatterplot3d', 'sessioninfo', 'shape', 'shiny', 'shinyBS', 'shinydashboard', 'shinyFiles', 'shinyjs', 'SingleCellExperiment', 'smoother', 'snow', 'sourcetools', 'sp', 'spam', 'SPARQL', 'SparseM', 'splancs', 'statmod', 'stringi', 'stringr', 'SummarizedExperiment', 'sys', 'testthat', 'TH.data', 'tibble', 'tidyr', 'tidyselect', 'tinytex', 'tsne', 'TTR', 'usethis', 'utf8', 'vcd', 'vctrs', 'vegan', 'VGAM', 'VIM', 'vipor', 'viridis', 'viridisLite', 'whisker', 'withr', 'xfun', 'XML', 'xml2', 'xopen', 'xtable', 'xts', 'XVector', 'yaml', 'zeallot', 'zip', 'zlibbioc', 'zoo')

installation_needed <- unlist(lapply(PACKAGES_TOTAL, require, character.only = TRUE, quietly = TRUE))
installation_needed <- PACKAGES_TOTAL[installation_needed == FALSE]

## Stop if not all required packages are installed
if(length(installation_needed) > 0) {stop(paste("\n\nNot all necessary packages are installed! Run the Installation Executable or contact the author. The following packages are missing:", paste(installation_needed, collapse = ", ")))}

## Set behaviour of functions using randomness to the same version, so results are the same regardless of R version
RNGversion("3.5.3")

```

# 2. Data Importing

```{r import, message = FALSE}

## Load and print used parameters for future reference
load(file = "../temp.RData")
message("Input Files: ", files)
message("Output Directory: ", outputdir)
print(paste("Input Files: ", files))
print(paste("Output Directory: ", outputdir))
print("User Defined Parameters: ")
params

## Unzip Zipped files
#zip_files <- list.files(pattern='.zip$', full=TRUE, ignore.case = TRUE)
#if (!isEmpty(zip_files)) {unzip(zipfile = zip_files)}
#fcs_files <- list.files(pattern='.fcs$', full=TRUE, ignore.case = TRUE)

## Concatenate if needed, load the FCS File and print its summary
if (!concat) {fcs <- read.FCS(filename = files, transformation = FALSE)} else {fcs <- concatFCS(x = files, file_num = TRUE)
write.FCS(fcs, filename = paste(outputdir,".fcs",sep=""))}
exprs <- as.data.frame(fcs@exprs)

if (is.null(exprs$FileNum)) {stop("This Single File was not concatenated using this Script! Please re-concatenate your file using this script.")}
samplenumber <- length(unique(exprs$FileNum))

fcs@parameters@data
t(summary(exprs))

```

# 3. Data Preprocessing

```{r preprocessing}

## Spillover Correction using Spillover Matrix 
if (params$SPILLOVER != "Do Nothing") {
  #spillovermatrix <- spillover(x = fcs, )
  spillovermatrix <- readxl::read_xlsx(path = params$SPILLOVERMATRIX)
  spillovermatrix <- tibble::column_to_rownames(spillovermatrix, colnames(spillovermatrix)[1])
  compensationmatrix <- spillovermatrix[rownames(spillovermatrix) %in% colnames(fcs@exprs), colnames(spillovermatrix) %in% colnames(fcs@exprs)]
  spillovermarkers <- rownames(compensationmatrix)  
  if (params$SPILLOVER == "Give Warnings & Compensate Data") {
    fcs_compensated <- compensate(x = fcs, spillover = compensationmatrix)
    exprs_compensated <- as.data.frame(fcs_compensated@exprs)
    t(summary(exprs_compensated))
  }
}

## Data Pre-Gating
pregating <- function(x, pregate) {
  message(paste("Applying Pregate", pregate));
  if (grepl("<", pregate, fixed=TRUE)) {filterargs <- strsplit(pregate, split = "<")[[1]]; exprs2 <- dplyr::filter(x, filterargs[1] < as.numeric(filterargs[2]) ) };
  if (grepl(">", pregate, fixed=TRUE)) {filterargs <- strsplit(pregate, split = ">")[[1]]; exprs2 <- dplyr::filter(x, filterargs[1] > as.numeric(filterargs[2]) ) };
  num_removed <- dim(x)[1] - dim(exprs2)[1] 
  print(paste("Pregate", pregate, "applied succesfully.", num_removed, "cells have been filtered out.")) 
  return(exprs2) }

pregates <- strsplit(params$pregates, split = " ")[[1]] 
for (pregate in pregates) {exprs <- pregating(exprs, pregate)}

## Channel Description
pregating_channels <- strsplit(params$pregating_channels, split = " ")[[1]]
pregating_channels <- pregating_channels[pregating_channels %in% colnames(exprs)]
instrument_channels <- strsplit(params$instrument_channels, split = " ")[[1]]
instrument_channels <- instrument_channels[instrument_channels %in% colnames(exprs)]
lineage_channels <- unlist(colnames(exprs))[!unlist(colnames(exprs)) %in% c(pregating_channels,instrument_channels)]

## Make colnames human readable using information in the parameter data slot
metalmarkers <- list()
markers <- gsub(pattern = ".*_", replacement = "", x = as.vector(fcs@parameters@data$desc));
if (params$markernames) {
  for (markerid in which(!is.na(markers))) {metalmarkers[[markers[markerid]]] <- colnames(exprs)[markerid]}
  colnames(exprs)[which(!is.na(markers))] <- markers[which(!is.na(markers))]
} else {for (markerid in which(!is.na(markers))) {metalmarkers[[colnames(exprs)[markerid]]] <- markers[markerid]}}

## Bead Normalization: Already performed by software before data import
## Compensation:       Already performed by software before data import
## Debarcoding:        Already performed by software before data import

## Arcsinh Data Transformation
message(paste("Arcsinh Data Transformation enabled:",params$arcsinh)); if (params$arcsinh) {
  require(MASS)
  require(RColorBrewer)
  k <- 11; my.cols <- rev(brewer.pal(k, "RdYlBu"))
  cofac <- params$arcsinhcofac
  #plot(exprs[,c("CD8", "CD4")], pch=".", col="grey", main="CD8 vs CD4")
  #z <- kde2d(exprs[,"CD8"], h = length(exprs[,"CD8"]), exprs[,"CD4"], n=50)
  #contour(z, drawlabels=FALSE, nlevels=k, col=my.cols, add=TRUE)
  exprs <- cbind(asinh(exprs[,c(pregating_channels, lineage_channels)]/cofac), exprs[,instrument_channels])
  #plot(exprs[,c("CD8", "CD4")], pch=".", col="grey", main="CD8 vs CD4 (transformed counts)")
  #z <- kde2d(exprs[,"CD8"], h = length(exprs[,"CD8"]), exprs[,"CD4"], n=50)
  #contour(z, drawlabels=FALSE, nlevels=k, col=my.cols, add=TRUE)
  t(summary(exprs))
}


## TODO: Batch Effects ?!?!
```

# 4. Clustering of Data

```{r clustering}

if (params$UMAP) {
umap_clustering <- umap(exprs)
}

if (params$TSNE) {
tsne_clustering <- tsne(exprs, perplexity = 10)
}

if (params$FLOWSOM) {
flowsom_clustering <- MetaClustering(data = exprs, max = 30)
}

```

# 5. Plotting of Dimension Reductions

```{r plotting}

setwd(outputdir)

if (params$UMAP) {
plot(umap_clustering)
}
  
if (params$TSNE) {
plot(tsne_clustering)
}

if (params$FLOWSOM) {
flowsom_clustering 
}

```

# 6. Saving Workspace Data

```{r saving}

setwd(outputdir)
save.image("R Workspace.RData")

```